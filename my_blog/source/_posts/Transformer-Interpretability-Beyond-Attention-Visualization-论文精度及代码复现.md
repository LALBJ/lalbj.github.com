---
title: Relevance Rollout，比 attention 更具可解释性的 transformer 解释方法
date: 2023-07-04 14:42:41
tags:
---

今天给大家分享一篇文章 《Transformer Interpretability Beyond Attention Visualization》。这篇文章是 2021 年 CVPR 的文章，这篇工作中提出了一套新的可解释性方法来对 transformer 进行可解释性分析。

transformer 的 attention 机制本身就能够输出具有一定可解释性的可视化结果，但是这套方案只能看到单个注意力块的结果，因此 rollout 应运而生。他能够累积所有注意力块的归因结果得到一个全局的归因，ViT 的解释分析方法使用的就是 rollout，但是 rollout 是一个静态的归因结果，因此作者在本文中提出一种 class-specific 的解释方法。在标题中，作者并没有明确得给自己的方法命名，所以这篇文章中为了书写方便将这个方法暂且称为 Relevance Rollout。

<!--more-->

## 摘要

这篇文章与 ViT 是同年发布的文章， ViT 一经发布后就席卷了 CV 领域的各个子任务，自然有人好奇 ViT 这个黑箱模型其中的机制到底是什么。

而之前针对 transformer 进行可解释的方法只有 transformer 文章中提及的注意力图也可称为显著性图、以及 2020 年 ACL 的一篇文章 Rollout 采用启发式的方法传播注意力图得到最终的归因结果。

作者提出的方法其实可以总结为两点，一是在 transformer 的可解释性工作中如何对注意力层做好解释分析，二是层与层之间残差连接结构的相关性做好分析是当前任务的难点，而作者提出的方法旨在解决这两个问题的。

最终，作者在一些在一些 transformer 网络以及一些任务中验证了其方法的有效性。

## 引言

现在 NLP 和 CV 领域的 sota 方法基本上都被 transformer based model 刷了一遍，而且今年大火的大模型的背后也是 transformer。因此，关于可视化 transformer 的决策过程的研究对于我们后续进一步开展相关研究至关重要。

transformer 的核心结构就是 self-attention layers，在自注意力层中会为每两个 token 之间分配一个注意力值。在 NLP 中，这个 token 就是一个单词或者单词的一部分，在 CV 领域 这个 token 可以是图像的一个 patch。

可视化 Transformer 模型有两种常见的方法，一种是将注意力作为相关性分数进行可视化，这种方法通常用于单个注意力层。另一种是连接多个层。也就是平均所有层的注意力值。然而这种方法假设层与层之间是某种简单的关系进行累加，会导致一些不相关的区域被高亮，例如 rollout 方法其实就是假设层与层之间是线性关系。

本文提出了一套可解释性方法。

第一步，引入能够适用于正值和负值的相关性传播规则

第二步，为非参数层提出了一个归一项

第三步，集成了注意力和相关性分数并连接了多个注意力块的集成结果

## 方法

在本文方法的第 3.1 和 3.2 章节都是在做一些定理的推导和证明，这里就不过多赘述和推导了。3.1 章节相关性和梯度，通过深度泰勒分解推导出相关性值的计算方式，以及非线性层正负激活值的处理问题。3.2 章节非参相关性传播，主要介绍了如果对于非参结构进行相关性值的传播以及通过乘法传播的过程可能会带来的相关性值爆炸的问题及归一化解决方式的形式化推导。

### 3.3 相关性和梯度扩散

在 ViT 中，采用的是多头自注意力结构，注意力头的数量即为 $h$，每一个头的特征维度为 $d_h$ 因此一个注意力块的总维度 $d = hd_h$。一个自注意力块被定义为下面的结构：

$A^{(b)} = softmax(\frac{ {Q^{(b)}} \cdot {K^{(b)}} }{\sqrt{d_h}})$

$O^{(b)} = A^{(b)} \cdot V^{(b)}$

其中，$Q^{(b)}, K^{(b)}, V^{(b)} \in \mathbb{R}^{h \times s \times d_h}$ 分别代表 query,key 和 value。

按照如上的定义， rollout 方法的计算为如下过程：

$\hat{A}^{(b)} = I + \mathbb{E_h}A^{(b)}$

$rollout = \hat{A}^{(1)} \cdot \hat{A}^{(2)} \cdot ... \cdot \hat{A}^{(B)}$

我们可以观察到 rollout 的结果是固定的，不会因目标类别的变化而产生影响。

本文的过程为如下形式：

$\overline{A}^{(b)} = I + \mathbb{E_h}(\bigtriangledown A^{(b)} \odot R^{(n_b)})^{+}$

$C = \overline{A}^{(1)} \cdot \overline{A}^{(2)} \cdot ... \cdot \overline{A}^{(B)}$

其中 $\mathbb{E_h}$ 是多个头输出结果的求平均得到的结果，而 $\bigtriangledown A^{(b)}$ 为注意力映射 $A^{(b)}$ 的梯度，$R^{(n_b)}$ 为相关值，其计算方式在 3.1 章节中有详细的介绍和推导，其实就是通过泰勒分解进行计算得到的值。

### 3.4 得到图片的归因映射

通过上述的方法得到的矩阵 $C$ 的大小为 $s \times s$。在常规的 ViT 结构中，$s$ 为 197，这里进行一个简要的介绍，想要更加详细了解的话可以读一下 ViT 和 Bert 的论文。在 ViT 中是将一个 $16 \times 16$ 的图像块作为一个 patch，因此对于一个 $224 \times 224$ 的图像输入进来，就会得到 $(224 \times 224) \div (16 \times 16)$ 也就是 196 个 token。在 ViT 中，参考了 Bert 的设计，在这 196 个 token 前加了一个 [CLS] token，用于下游的分类任务。从下图即 ViT 的架构图中就能清晰得看出来这一设计。

![](/images/R_Rollout/ViT.png)


因此我们最后得到的矩阵 $C$ 的大小为 $197 \times 197$，下一步就是实现从这个相关性矩阵到图像归因结果的映射了。这个步骤，在原文的代码中是通过 $C[0, 1:]$ 这个操作来实现的。在理解了，ViT 结构的 token 的内涵后，对于这一设计也很容易理解。首先，这个相关性矩阵的每一行就是每一个 token 与别的 token 的相关性映射。而只有第一个 [CLS] token 中包含类别信息，因此我们需要取出他，然而 [CLS] token 与他本身的映射关系在图像中是没有映射关系的，所以只取出了后 196 个值，也即 [CLS] token 与各个 patch token 的映射。最后，我们得到一个 $14 \times 14$ 的矩阵，再通过双线性插值上采样到原始图像尺寸。

整个算法完整的过程如下图所示：

![](/images/R_Rollout/R_Rollout.png)

## 4 实验

首先是定性实验，也就是提供了一些示例的不同方法的归因结果对比，分别是无类别归因和类别归因结果。

![](/images/R_Rollout/sample_results.png)

![](/images/R_Rollout/class_specific.png)

然后是扰动实验，即基于归因结果按照相关值从小到大和从大到小的顺序去进行 mask 得出对于预测的影响计算得到 AUC。

![](/images/R_Rollout/perturbation.png)

接下来分别是分割实验和 Bert 归因实验的结果

![](/images/R_Rollout/segment.png)

![](/images/R_Rollout/Bert.png)

在消融实验中，作者测试了不使用梯度信息，只对第一个注意力块和最后一个注意力块进行计算 这三个消融实验设置下的不同结果。

![](/images/R_Rollout/alation.png)


## 5 结语

在结语中，作者主要提到了几个点值得关注：

- 与 CNN 相比， Transformer 中的非正激活函数，跳跃连接以及对自注意力矩阵乘法的建模等问题对于模型可解释来说都是很大的挑战。（黑盒模型则不需要关注于这些挑战，但是黑盒模型的时间效率太低了

- 可能是受限于注意力本身机制的问题，通过本文方法得到的解释结果依然存在碎片化解释的问题